{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extended use of Huggingface's Zero-Shot Pipeline\n",
        "\n",
        "- In this notebook, we extend the last notebook's zero-shot learning while using custom sentences and labels to classify those texts.  \n",
        "- You will also see, how multi-lingual transformer models can be used to perform various tasks in many languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TiU_ES5tzpMH"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "spkccRiv0CB3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to FacebookAI/roberta-large-mnli and revision 130fb28 (https://huggingface.co/FacebookAI/roberta-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/Users/emna/bootcamp/week10/ds-intro-to-NLP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "2026-02-09 21:05:17.759841: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
            "2026-02-09 21:05:17.759866: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
            "2026-02-09 21:05:17.759871: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
            "2026-02-09 21:05:17.759886: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2026-02-09 21:05:17.759896: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
            "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", device=0) # to utilize GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWiovVJG9ei_"
      },
      "source": [
        "We can use this pipeline by passing in a sequence and a list of candidate labels. The pipeline assumes by default that only one of the candidate labels is true, returning a list of scores for each label which add up to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We create a function to display our predictions from the model in a tabular form\n",
        "\"\"\"\n",
        "def get_predictions_score(prediction):\n",
        "    pred_labels = prediction['labels']\n",
        "    pred_scores = prediction['scores']\n",
        "    seq = [prediction['sequence']]\n",
        "    return  pd.concat([\n",
        "                pd.DataFrame(seq),\n",
        "                pd.DataFrame(pred_labels),\n",
        "                pd.DataFrame(pred_scores),\n",
        "            ], axis=1, ignore_index=True).rename(columns={0:'Sequence',1:'Labels', 2:'Probability'}).set_index(['Sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Amazon is the longest river in the world</th>\n",
              "      <td>geography</td>\n",
              "      <td>0.870195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>delivery</td>\n",
              "      <td>0.129805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Labels  Probability\n",
              "Sequence                                                        \n",
              "Amazon is the longest river in the world  geography     0.870195\n",
              "NaN                                        delivery     0.129805"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"Amazon is the longest river in the world\"\n",
        "candidate_labels = [\"geography\",  \"delivery\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What if we change some spellings? Here we change Amazon -> amazon. It doesn't make much difference but in some cases it will. <br> Try playing with spellings and adding or removing labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>amazon is the longest river in the world</th>\n",
              "      <td>geography</td>\n",
              "      <td>0.805672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>delivery</td>\n",
              "      <td>0.194328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Labels  Probability\n",
              "Sequence                                                        \n",
              "amazon is the longest river in the world  geography     0.805672\n",
              "NaN                                        delivery     0.194328"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"amazon is the longest river in the world\"\n",
        "candidate_labels = [\"geography\",  \"delivery\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>amazon is the longest river in the World</th>\n",
              "      <td>geography</td>\n",
              "      <td>0.768614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>delivery</td>\n",
              "      <td>0.231386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Labels  Probability\n",
              "Sequence                                                        \n",
              "amazon is the longest river in the World  geography     0.768614\n",
              "NaN                                        delivery     0.231386"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"amazon is the longest river in the World\"\n",
        "candidate_labels = [\"geography\",  \"delivery\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>amazon is the longest river in the world</th>\n",
              "      <td>water</td>\n",
              "      <td>0.682985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>nature</td>\n",
              "      <td>0.165954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>geography</td>\n",
              "      <td>0.151062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Labels  Probability\n",
              "Sequence                                                        \n",
              "amazon is the longest river in the world      water     0.682985\n",
              "NaN                                          nature     0.165954\n",
              "NaN                                       geography     0.151062"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"amazon is the longest river in the world\"\n",
        "candidate_labels = [\"geography\", \"nature\", \"water\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the example below, you'll see how good are these models in understanding the context, with a slight spelling mistake. <br> Try changing the spelling and observe the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>are we going to Oktoberfest?</th>\n",
              "      <td>wine</td>\n",
              "      <td>0.489264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>Munich</td>\n",
              "      <td>0.160479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>sausage</td>\n",
              "      <td>0.132136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>food</td>\n",
              "      <td>0.091373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>bear</td>\n",
              "      <td>0.085948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>pretzel</td>\n",
              "      <td>0.040801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Labels  Probability\n",
              "Sequence                                          \n",
              "are we going to Oktoberfest?     wine     0.489264\n",
              "NaN                            Munich     0.160479\n",
              "NaN                           sausage     0.132136\n",
              "NaN                              food     0.091373\n",
              "NaN                              bear     0.085948\n",
              "NaN                           pretzel     0.040801"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"are we going to Oktoberfest?\"\n",
        "candidate_labels = [\"food\", \"Munich\", \"bear\", \"wine\", \"pretzel\", \"sausage\"] ## What if you change bear (animal) -> beer (drink)\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>are we going to Oktoberfest?</th>\n",
              "      <td>beer</td>\n",
              "      <td>0.531387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>wine</td>\n",
              "      <td>0.250834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>Munich</td>\n",
              "      <td>0.082274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>sausage</td>\n",
              "      <td>0.067743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>food</td>\n",
              "      <td>0.046845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>pretzel</td>\n",
              "      <td>0.020918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Labels  Probability\n",
              "Sequence                                          \n",
              "are we going to Oktoberfest?     beer     0.531387\n",
              "NaN                              wine     0.250834\n",
              "NaN                            Munich     0.082274\n",
              "NaN                           sausage     0.067743\n",
              "NaN                              food     0.046845\n",
              "NaN                           pretzel     0.020918"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"are we going to Oktoberfest?\"\n",
        "candidate_labels = [\"food\", \"Munich\", \"beer\", \"wine\", \"pretzel\", \"sausage\"] ## What if you change bear (animal) -> beer (drink)\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "hkfE6NRA0Dzy",
        "outputId": "8b3f9e37-3e46-4b25-813b-c5fa7bbc3c97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Who are you voting for in 2020?</th>\n",
              "      <td>america</td>\n",
              "      <td>0.397640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>public health</td>\n",
              "      <td>0.213483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>plants</td>\n",
              "      <td>0.137286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>fruits</td>\n",
              "      <td>0.133617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>food</td>\n",
              "      <td>0.117974</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Labels  Probability\n",
              "Sequence                                                   \n",
              "Who are you voting for in 2020?        america     0.397640\n",
              "NaN                              public health     0.213483\n",
              "NaN                                     plants     0.137286\n",
              "NaN                                     fruits     0.133617\n",
              "NaN                                       food     0.117974"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"food\", \"public health\", \"plants\", \"fruits\",\"america\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### The predictions are poor as the labels are not related to the sequence. But there are ways to improve upon this. We can provide related target labels for the input sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Who are you voting for in 2020?</th>\n",
              "      <td>politics</td>\n",
              "      <td>0.503332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>elections</td>\n",
              "      <td>0.447219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>president</td>\n",
              "      <td>0.022313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>america</td>\n",
              "      <td>0.014836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>democrate</td>\n",
              "      <td>0.006287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>republican</td>\n",
              "      <td>0.006012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Labels  Probability\n",
              "Sequence                                                \n",
              "Who are you voting for in 2020?    politics     0.503332\n",
              "NaN                               elections     0.447219\n",
              "NaN                               president     0.022313\n",
              "NaN                                 america     0.014836\n",
              "NaN                               democrate     0.006287\n",
              "NaN                              republican     0.006012"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Think about other labels which can improve the predictions\n",
        "## HINT: Labels related to your text\n",
        "sequence = \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"elections\",\"america\",\"president\",\"politics\",\"republican\",\"democrate\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGXwxxyn9nOC"
      },
      "source": [
        "To do multi-class classification, simply pass `multi_class=True`. In this case, the scores will be independent, but each will fall between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "ZvZeVb2h5RX0",
        "outputId": "9ba085bf-4c52-4011-9c51-3a0adeddd3a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Who are you voting for in 2020?</th>\n",
              "      <td>politics</td>\n",
              "      <td>0.996493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>elections</td>\n",
              "      <td>0.993664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>economics</td>\n",
              "      <td>0.063439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>public health</td>\n",
              "      <td>0.054792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Labels  Probability\n",
              "Sequence                                                   \n",
              "Who are you voting for in 2020?       politics     0.996493\n",
              "NaN                                  elections     0.993664\n",
              "NaN                                  economics     0.063439\n",
              "NaN                              public health     0.054792"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"politics\", \"public health\", \"economics\", \"elections\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels, multi_label=True)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLLeDT1r9-yQ"
      },
      "source": [
        "Here's an example of sentiment classification: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "f7AF53Wl5f8W",
        "outputId": "50a52076-7d2b-4ce0-b95f-c9cf9a13b361"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>I hated this movie. The acting sucked.</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.995728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.004272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Labels  Probability\n",
              "Sequence                                                     \n",
              "I hated this movie. The acting sucked.  negative     0.995728\n",
              "NaN                                     positive     0.004272"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"I hated this movie. The acting sucked.\"\n",
        "candidate_labels = [\"positive\", \"negative\"]\n",
        "\n",
        "pred = classifier(sequence, candidate_labels)\n",
        "get_predictions_score(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSoBpCpV6k4s"
      },
      "source": [
        "So how does this method work?\n",
        "\n",
        "The underlying model is trained on the task of Natural Language Inference (NLI), which takes in two sequences and determines whether they contradict each other, entail each other, or neither.\n",
        "\n",
        "This can be adapted to the task of zero-shot classification by treating the sequence which we want to classify as one NLI sequence (called the premise) and turning a candidate label into the other (the hypothesis). If the model predicts that the constructed premise _entails_ the hypothesis, then we can take that as a prediction that the label applies to the text. Check out [this blog post](https://joeddav.github.io/blog/2020/05/29/ZSL.html) for a more detailed explanation.\n",
        "\n",
        "By default, the pipeline turns labels into hypotheses with the template `This example is {class_name}.`. This works well in many settings, but you can also customize this for your specific setting. Let's add another review to our above sentiment classification example that's a bit more challenging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "5yLx3pRr5xQA",
        "outputId": "6420fb46-9aeb-4055-8ab6-fdc5eb822a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sequence': 'I hated this movie. The acting sucked.',\n",
              "  'labels': ['negative', 'positive'],\n",
              "  'scores': [0.9957284331321716, 0.004271592944860458]},\n",
              " {'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\",\n",
              "  'labels': ['positive', 'negative'],\n",
              "  'scores': [0.8578121662139893, 0.14218787848949432]}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences = [\n",
        "    \"I hated this movie. The acting sucked.\",\n",
        "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
        "]\n",
        "candidate_labels = [\"positive\", \"negative\"]\n",
        "\n",
        "classifier(sequences, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrpyGWM782R"
      },
      "source": [
        "The second example is a bit harder. Let's see if we can improve the results by using a hypothesis template which is more specific to the setting of review sentiment analysis. Instead of the default, `This example is {}.`, we'll use, `The sentiment of this review is {}.` (where `{}` is replaced with the candidate class name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "kqx5hp7X8XNA",
        "outputId": "69c6e083-f3dc-41db-fca5-d96a3541f1fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sequence': 'I hated this movie. The acting sucked.',\n",
              "  'labels': ['negative', 'positive'],\n",
              "  'scores': [0.9941108822822571, 0.0058891079388558865]},\n",
              " {'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\",\n",
              "  'labels': ['positive', 'negative'],\n",
              "  'scores': [0.9871302247047424, 0.01286973338574171]}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences = [\n",
        "    \"I hated this movie. The acting sucked.\",\n",
        "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
        "]\n",
        "candidate_labels = [\"positive\", \"negative\"]\n",
        "hypothesis_template = \"The sentiment of this review is {}.\"\n",
        "\n",
        "classifier(sequences, candidate_labels, hypothesis_template=hypothesis_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iArbRAe781-_"
      },
      "source": [
        "By providing a more precise hypothesis template, we are able to see a more accurate classification of the second review.\n",
        "\n",
        "> Note that sentiment classification is used here just as an illustrative example. The [Hugging Face Model Hub](https://huggingface.co/models?filter=text-classification) has a number of models trained specifically on sentiment tasks which can be used instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxUTOnllSH4w"
      },
      "source": [
        "#### Zero-shot classification in more than 100 languages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Interested in using the pipeline for languages other than English? There is a cross-lingual model on top of XLM RoBERTa which you can use by passing `model='joeddav/xlm-roberta-large-xnli'` when creating the pipeline: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "siZhFPekSN7t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/emna/bootcamp/week10/ds-intro-to-NLP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5337b1c787548779c3997e2b9089753",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/734 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50595c684d7049cfad612ab637e85287",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFXLMRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLMRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFXLMRobertaForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27171f7ecafc48d598166deeffde9e26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "875d871246e345abb3db472708590dca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a9ff1cc5c9e4b3ea64824d423a9ee53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model='joeddav/xlm-roberta-large-xnli', device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrcljZ75UxKN"
      },
      "source": [
        "You can use it with any combination of languages. For example, let's classify a Russian sentence with English candidate labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "gBJyFwC2TwGv",
        "outputId": "5e683b8a-2e9f-46c2-95f9-04559bed04ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'За кого вы голосуете в 2020 году?',\n",
              " 'labels': ['politics', 'Europe', 'public health'],\n",
              " 'scores': [0.904848575592041, 0.05722159147262573, 0.03792988136410713]}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"Europe\", \"public health\", \"politics\"]\n",
        "\n",
        "classifier(sequence, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9hGVMsrVI8S"
      },
      "source": [
        "Now let's do the same but with the labels in French:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "0xKYBOLYVeNJ",
        "outputId": "a8066bb5-9e95-4f80-d77b-9753cc4c4be3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'За кого вы голосуете в 2020 году?',\n",
              " 'labels': ['politique', 'Europe', 'santé publique'],\n",
              " 'scores': [0.9726150035858154, 0.01712874136865139, 0.010256249457597733]}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"Europe\", \"santé publique\", \"politique\"]\n",
        "\n",
        "classifier(sequence, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHURJUPCVgGP"
      },
      "source": [
        "As we discussed in the last section, the default hypothesis template is the English, `This text is {}.`. If you are working strictly within one language, it may be worthwhile to translate this to the language you are working with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ZCtTclt7VpMv",
        "outputId": "87c768b3-2193-4164-d993-0ee9c9eec3ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': '¿A quién vas a votar en 2020?',\n",
              " 'labels': ['política', 'Europa', 'salud pública'],\n",
              " 'scores': [0.9109603762626648, 0.05954741686582565, 0.02949213795363903]}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"¿A quién vas a votar en 2020?\"\n",
        "candidate_labels = [\"Europa\", \"salud pública\", \"política\"]\n",
        "hypothesis_template = \"Este ejemplo es {}.\"\n",
        "\n",
        "classifier(sequence, candidate_labels, hypothesis_template=hypothesis_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQyVNE2fTDVs"
      },
      "source": [
        "The model is fine-tuned on XNLI which includes 15 languages: Arabic, Bulgarian, Chinese, English, French, German, Greek, Hindi, Russian, Spanish, Swahili, Thai, Turkish, Urdu, and Vietnamese. The base model is trained on 85 more, so the model will work to some degree for any of those in the XLM RoBERTa training corpus (see the full list in appendix A of the [XLM Roberata paper](https://arxiv.org/abs/1911.02116)).\n",
        "\n",
        "See the [model page](https://huggingface.co/joeddav/xlm-roberta-large-xnli) for more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Different Pipeline models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Read here](https://huggingface.co/docs/transformers/main_classes/pipelines) about different models available from Huggingface pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74520add39914e759079505d5761dd55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f95460c85d84bb8a56dc50d604362f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfdbd07532a847f583608f398217267c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce192feb3274fa298cbe082e083c2c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "824eb3f625fe4487875bdc25b0d61068",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "844368f67a904749bc566d320a846c4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text_gen = pipeline(\"text-generation\", model='gpt2') # to utilize GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': \"Data Science is cool right now because I'm pretty good at it. But it's hard to do much except get my hands on a few years on\"},\n",
              " {'generated_text': 'Data Science is cool! And I would love to see more of your research involved in your project!\\n\\nFor more info'},\n",
              " {'generated_text': \"Data Science is cool, but why wouldn't it be cool for anyone in the gaming community to see their games and videos disappear from YouTube? The game\"}]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Data Science is cool\"\n",
        "text_gen(prompt, max_length=30, num_return_sequences=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'Gambling is a serious problem in the United States, with over 2.3 million reported gambling crimes each year and nearly $2 billion going to criminals'},\n",
              " {'generated_text': 'Gambling is such an integral part of modern sports, it is almost impossible to describe what is gambling like without having actually seen it. We all know'},\n",
              " {'generated_text': 'Gambling is the new $5 billion that allows wealthy investors to invest and control millions of dollars in Bitcoin.\\n\\nBitcoin is one of the most'}]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Gambling is\"\n",
        "text_gen(prompt, max_length=30, num_return_sequences=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'crypto is not going away.\\n\\nWith the exception of the very last bitcoin, which is already dead, the crypto revolution has made bitcoin more'},\n",
              " {'generated_text': 'crypto is getting more and more people to think about cryptocurrency, and I think people are starting to realize that I don\\'t give a shit.\"\\n'},\n",
              " {'generated_text': \"crypto is a public protocol that was invented back in 1986 by some people. I've actually heard about it back then (including the original BNet\"}]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"crypto is\"\n",
        "text_gen(prompt, max_length=30, num_return_sequences=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can play around with different starting sentence. You can change `max_length` argument if you want shorter or longer sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The sentiment analysis example in the beginning of the notebook can also be done using a sentiment analysis pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Create a new sentiment-analysis pipeline and play with the examples in the new pipeline\n",
        "## HINT: You don't need to provide labels to the sentiment analysis pipeline as it is trained for the same task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OPTIONAL\n",
        "#### You can create a Hugging face account and create a token if you wish to create or push content to a repository (e.g., when training a model or modifying a model card) within hugging face.\n",
        "\n",
        "- Create an account at https://huggingface.co/\n",
        "- After logging in\n",
        "    - go to Settings->Access Tokens\n",
        "    - Create new token and give write permissions\n",
        "\n",
        "- Run these commands \n",
        "    - `brew install huggingface-cli`\n",
        "    - `huggingface-cli login` and paste the access token from huggingface\n",
        "    - **Do not add access token for github if it asks**\n",
        "\n",
        "    Reference: https://huggingface.co/docs/hub/security-tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
