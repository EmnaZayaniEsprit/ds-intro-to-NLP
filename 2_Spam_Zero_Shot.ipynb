{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load useful libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/SMSSpamCollection.txt\",\n",
    "    encoding=\"utf-8\",\n",
    "    header=None,\n",
    "    delimiter=\"\\t\",\n",
    "    names=[\"target\", \"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5572 rows in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {data.shape[0]} rows in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the pipeline in one-line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to FacebookAI/roberta-large-mnli and revision 130fb28 (https://huggingface.co/FacebookAI/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",device = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model works best with informative labels, spam/ham are not so informative. Using spam/ham leads to a Hamming loss of 53% vs using click bait/written by humans leading to 19%\n",
    "\n",
    "Can you find better label descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {\"spam\":\"click bait\", \"ham\":\"written by humans\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "candidate_labels = list(category_map.values())\n",
    "predictedCategories = []\n",
    "trueCategories = []\n",
    "for i in tqdm(range(100)):\n",
    "    text = data.iloc[i,]['text']\n",
    "    cat = [data.iloc[i,]['target']]\n",
    "    res = classifier(text, candidate_labels, multi_label=False)\n",
    "    labels = res['labels'] \n",
    "    scores = res['scores'] #extracting the scores associated with the labels\n",
    "    res_dict = {label : score for label,score in zip(labels, scores)}\n",
    "    sorted_dict = dict(sorted(res_dict.items(), key=lambda x:x[1],reverse = True)) #sorting the dictionary of labels in descending order based on their score\n",
    "    categories  = next(k for i, (k,v) in enumerate(sorted_dict.items()))\n",
    "\n",
    "    predictedCategories.append(categories)\n",
    "    trueCats = [category_map[x] for x in cat]\n",
    "    trueCategories.append(trueCats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Categories ['written by humans']\n",
      "Predicted Categories written by humans\n",
      "##################################################\n",
      "True Categories ['written by humans']\n",
      "Predicted Categories written by humans\n",
      "##################################################\n",
      "True Categories ['click bait']\n",
      "Predicted Categories written by humans\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "for y_true, y_pred in zip(trueCategories[:3], predictedCategories[:3]):\n",
    "    print(f'True Categories {y_true}')\n",
    "    print(f'Predicted Categories {y_pred}')\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'written by humans'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'click bait',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'written by humans',\n",
       " 'click bait']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming Loss\n",
    "The Hamming loss is the fraction of labels that are incorrectly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hamming loss is 0.1900 compared to 0.0237 from the last trained model in Notebook 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "print(f'The hamming loss is {hamming_loss(trueCategories,predictedCategories):.4f} compared to 0.0237 from the last trained model in Notebook 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your understanding\n",
    "\n",
    "Can you find better \"labels\" for the category description improve the Hamming Loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Categories ['written by humans']\n",
      "Predicted Categories advertising\n",
      "##################################################\n",
      "True Categories ['written by humans']\n",
      "Predicted Categories written by humans\n",
      "##################################################\n",
      "True Categories ['advertising']\n",
      "Predicted Categories written by humans\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "category_map = {\"spam\":\"advertising\", \"ham\":\"written by humans\"}\n",
    "\n",
    "candidate_labels = list(category_map.values())\n",
    "predictedCategories = []\n",
    "trueCategories = []\n",
    "for i in tqdm(range(100)):\n",
    "    text = data.iloc[i,]['text']\n",
    "    cat = [data.iloc[i,]['target']]\n",
    "    res = classifier(text, candidate_labels, multi_label=False)\n",
    "    labels = res['labels'] \n",
    "    scores = res['scores'] #extracting the scores associated with the labels\n",
    "    res_dict = {label : score for label,score in zip(labels, scores)}\n",
    "    sorted_dict = dict(sorted(res_dict.items(), key=lambda x:x[1],reverse = True)) #sorting the dictionary of labels in descending order based on their score\n",
    "    categories  = next(k for i, (k,v) in enumerate(sorted_dict.items()))\n",
    "\n",
    "    predictedCategories.append(categories)\n",
    "    trueCats = [category_map[x] for x in cat]\n",
    "    trueCategories.append(trueCats)\n",
    "    \n",
    "for y_true, y_pred in zip(trueCategories[:3], predictedCategories[:3]):\n",
    "    print(f'True Categories {y_true}')\n",
    "    print(f'Predicted Categories {y_pred}')\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hamming loss is 0.1600 compared to 0.0237 from the last trained model in Notebook 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "print(f'The hamming loss is {hamming_loss(trueCategories,predictedCategories):.4f} compared to 0.0237 from the last trained model in Notebook 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
